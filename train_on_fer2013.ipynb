{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Conv2D, Activation, MaxPool2D, Dropout, Dense, BatchNormalization, Flatten\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv(\"fer2013.csv\")\n",
    "ds.head()\n",
    "#0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35882</th>\n",
       "      <td>6</td>\n",
       "      <td>50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35883</th>\n",
       "      <td>3</td>\n",
       "      <td>178 174 172 173 181 188 191 194 196 199 200 20...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35884</th>\n",
       "      <td>0</td>\n",
       "      <td>17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35885</th>\n",
       "      <td>3</td>\n",
       "      <td>30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35886</th>\n",
       "      <td>2</td>\n",
       "      <td>19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotion                                             pixels        Usage\n",
       "35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...  PrivateTest\n",
       "35883        3  178 174 172 173 181 188 191 194 196 199 200 20...  PrivateTest\n",
       "35884        0  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...  PrivateTest\n",
       "35885        3  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...  PrivateTest\n",
       "35886        2  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...  PrivateTest"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training       28709\n",
       "PrivateTest     3589\n",
       "PublicTest      3589\n",
       "Name: Usage, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"Usage\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28709, 2304), (3589, 2304))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = ds[[\"emotion\", \"pixels\"]][ds[\"Usage\"] == \"Training\"]\n",
    "train['pixels'] = train['pixels'].apply(lambda x: np.fromstring(x, sep=' '))\n",
    "train_pix = np.vstack(train['pixels'].values)\n",
    "test = ds[[\"emotion\", \"pixels\"]][ds[\"Usage\"] == \"PublicTest\"]\n",
    "test['pixels'] = test['pixels'].apply(lambda x: np.fromstring(x, sep=' '))\n",
    "test_pix = np.vstack(test['pixels'].values)\n",
    "train_pix.shape, test_pix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28709,), (3589,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\n",
    "#0=angry, 1=disgust+fear+surprise, 3=Happy, 4=sad, 6= neutral\n",
    "#apending 2 and 5 to 1; 5 to 2; 6 to 4\n",
    "#:::: set append = false to avoid changes\n",
    "def e_ind(x):\n",
    "    if(x==2 or x==5):\n",
    "        return 1\n",
    "    elif(x==5):\n",
    "        return 2\n",
    "    elif(x==6):\n",
    "        return 4\n",
    "    else:\n",
    "        return x\n",
    "F_S_D = True\n",
    "if(F_S_D):\n",
    "    train['emotion'] = train['emotion'].apply(lambda x: e_ind(x))\n",
    "    test['emotion'] = test['emotion'].apply(lambda x: e_ind(x))\n",
    "train_ind = np.array(train[\"emotion\"])\n",
    "test_ind = np.array(test[\"emotion\"])\n",
    "train_ind.shape, test_ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28709, 5), (3589, 5))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pix = train_pix.reshape(-1,48,48,1)\n",
    "train_ind = np_utils.to_categorical(train_ind)\n",
    "test_pix = test_pix.reshape(-1,48,48,1)\n",
    "test_ind = np_utils.to_categorical(test_ind)\n",
    "train_ind.shape, test_ind.shape\n",
    "#train_pix.shape, test_pix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 1799      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 1,604,623\n",
      "Trainable params: 1,602,191\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 1st stage\n",
    "model.add(Conv2D(32, 3, input_shape=(48, 48, 1), padding='same', \n",
    "                 activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, 3, padding='same', \n",
    "                 activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "# 2nd stage\n",
    "model.add(Conv2D(64, 3, padding='same', \n",
    "                 activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, 3, padding='same', \n",
    "                 activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 3rd stage\n",
    "model.add(Conv2D(128, 3, padding='same', \n",
    "                 activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, 3, padding='same', \n",
    "                 activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# FC layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(7))\n",
    "model.add(Activation('softmax'))\n",
    "if(F_S_D):\n",
    "    model.add(Dense(5))\n",
    "else:\n",
    "    model.add(Dense(7))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/10\n",
      " - 1521s - loss: 1.0232 - acc: 0.6156 - val_loss: 0.9747 - val_acc: 0.6381\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.97472, saving model to chkPt3.h5\n",
      "Epoch 2/10\n",
      " - 1511s - loss: 0.9535 - acc: 0.6481 - val_loss: 0.9559 - val_acc: 0.6431\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.97472 to 0.95590, saving model to chkPt3.h5\n",
      "Epoch 3/10\n",
      " - 1509s - loss: 0.9188 - acc: 0.6587 - val_loss: 0.9838 - val_acc: 0.6283\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.95590\n",
      "Epoch 4/10\n",
      " - 1512s - loss: 0.8836 - acc: 0.6739 - val_loss: 0.9035 - val_acc: 0.6626\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.95590 to 0.90349, saving model to chkPt3.h5\n",
      "Epoch 5/10\n",
      " - 1516s - loss: 0.8527 - acc: 0.6842 - val_loss: 0.8802 - val_acc: 0.6712\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.90349 to 0.88020, saving model to chkPt3.h5\n",
      "Epoch 6/10\n",
      " - 1678s - loss: 0.8236 - acc: 0.6984 - val_loss: 0.9045 - val_acc: 0.6606\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.88020\n",
      "Epoch 7/10\n",
      " - 1823s - loss: 0.7964 - acc: 0.7089 - val_loss: 0.8876 - val_acc: 0.6707\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.88020\n",
      "Epoch 8/10\n",
      " - 1719s - loss: 0.7756 - acc: 0.7159 - val_loss: 0.8222 - val_acc: 0.6971\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.88020 to 0.82218, saving model to chkPt3.h5\n",
      "Epoch 9/10\n",
      " - 1541s - loss: 0.7467 - acc: 0.7302 - val_loss: 0.8803 - val_acc: 0.6734\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.82218\n",
      "Epoch 10/10\n",
      " - 1661s - loss: 0.7181 - acc: 0.7394 - val_loss: 0.8230 - val_acc: 0.6991\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.82218\n"
     ]
    }
   ],
   "source": [
    "checkPoint = ModelCheckpoint(filepath='chkPt3.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "res = model.fit(train_pix, train_ind, epochs=10,\n",
    "                 shuffle=True,\n",
    "                 batch_size=100, \n",
    "                 validation_data=(test_pix, test_ind),\n",
    "                 callbacks=[checkPoint], \n",
    "                 verbose=2)\n",
    "\n",
    "# save model to json\n",
    "mod1_json = model.to_json()\n",
    "with open(\"model3.json\", \"w\") as json_file:\n",
    "    json_file.write(mod1_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
